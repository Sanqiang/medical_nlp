package medical_classify;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.List;

import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.parser.nndep.DependencyParser;
import edu.stanford.nlp.process.DocumentPreprocessor;
import edu.stanford.nlp.tagger.maxent.MaxentTagger;

public class Process {

	protected ArrayList<String> _docs = null;

	public Process() {
		this._docs = new ArrayList<String>();
		try {
			BufferedReader reader = new BufferedReader(new FileReader(new File(Config.PATH_DATA)));
			String line = null;
			while (null != (line = reader.readLine())) {
				String[] items = line.split("\t");
				this._docs.add(items[2]);
			}
			reader.close();
		} catch (FileNotFoundException e) {
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	MaxentTagger tagger = Module.getInst().getTagger();
	DependencyParser parser = Module.getInst().getDependencyParser();
	
	public void process() {
		for (String doc : _docs) {
			DocumentPreprocessor tokenizer = new DocumentPreprocessor(new StringReader(doc));
			for (List<HasWord> token_part : tokenizer) {
				
			}
		}
	}

}
